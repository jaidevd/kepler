backend: tensorflow
class_name: Model
config:
  input_layers:
  - [the_input, 0, 0]
  - [the_labels, 0, 0]
  - [input_length, 0, 0]
  - [label_length, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 128, 64, 1]
      dtype: float32
      name: the_input
      sparse: false
    inbound_nodes: []
    name: the_input
  - class_name: Conv2D
    config:
      activation: relu
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: &id002 !!python/tuple [1, 1]
      filters: 16
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: &id003 !!python/tuple [3, 3]
      name: conv1
      padding: same
      strides: &id004 !!python/tuple [1, 1]
      trainable: true
      use_bias: true
    inbound_nodes:
    - - - the_input
        - 0
        - 0
        - {}
    name: conv1
  - class_name: MaxPooling2D
    config:
      data_format: channels_last
      name: max1
      padding: valid
      pool_size: &id001 !!python/tuple [2, 2]
      strides: *id001
      trainable: true
    inbound_nodes:
    - - - conv1
        - 0
        - 0
        - {}
    name: max1
  - class_name: Conv2D
    config:
      activation: relu
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      data_format: channels_last
      dilation_rate: *id002
      filters: 16
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      kernel_size: *id003
      name: conv2
      padding: same
      strides: *id004
      trainable: true
      use_bias: true
    inbound_nodes:
    - - - max1
        - 0
        - 0
        - {}
    name: conv2
  - class_name: MaxPooling2D
    config:
      data_format: channels_last
      name: max2
      padding: valid
      pool_size: &id005 !!python/tuple [2, 2]
      strides: *id005
      trainable: true
    inbound_nodes:
    - - - conv2
        - 0
        - 0
        - {}
    name: max2
  - class_name: Reshape
    config:
      name: reshape
      target_shape: !!python/tuple [32, 256]
      trainable: true
    inbound_nodes:
    - - - max2
        - 0
        - 0
        - {}
    name: reshape
  - class_name: Dense
    config:
      activation: relu
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
      kernel_regularizer: null
      name: dense1
      trainable: true
      units: 32
      use_bias: true
    inbound_nodes:
    - - - reshape
        - 0
        - 0
        - {}
    name: dense1
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 1
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: gru1
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      reset_after: false
      return_sequences: true
      return_state: false
      stateful: false
      trainable: true
      units: 512
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - dense1
        - 0
        - 0
        - {}
    name: gru1
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: true
      implementation: 1
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: gru1_b
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      reset_after: false
      return_sequences: true
      return_state: false
      stateful: false
      trainable: true
      units: 512
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - dense1
        - 0
        - 0
        - {}
    name: gru1_b
  - class_name: Add
    config: {name: add_1, trainable: true}
    inbound_nodes:
    - - - gru1
        - 0
        - 0
        - &id006 {}
      - - gru1_b
        - 0
        - 0
        - *id006
    name: add_1
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 1
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: gru2
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      reset_after: false
      return_sequences: true
      return_state: false
      stateful: false
      trainable: true
      units: 512
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - add_1
        - 0
        - 0
        - {}
    name: gru2
  - class_name: GRU
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: true
      implementation: 1
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: gru2_b
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      reset_after: false
      return_sequences: true
      return_state: false
      stateful: false
      trainable: true
      units: 512
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - add_1
        - 0
        - 0
        - {}
    name: gru2_b
  - class_name: Concatenate
    config: {axis: -1, name: concatenate_1, trainable: true}
    inbound_nodes:
    - - - gru2
        - 0
        - 0
        - &id007 {}
      - - gru2_b
        - 0
        - 0
        - *id007
    name: concatenate_1
  - class_name: Dense
    config:
      activation: linear
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: normal, mode: fan_in, scale: 2.0, seed: null}
      kernel_regularizer: null
      name: dense2
      trainable: true
      units: 28
      use_bias: true
    inbound_nodes:
    - - - concatenate_1
        - 0
        - 0
        - {}
    name: dense2
  - class_name: Activation
    config: {activation: softmax, name: softmax, trainable: true}
    inbound_nodes:
    - - - dense2
        - 0
        - 0
        - {}
    name: softmax
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 16]
      dtype: float32
      name: the_labels
      sparse: false
    inbound_nodes: []
    name: the_labels
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 1]
      dtype: int64
      name: input_length
      sparse: false
    inbound_nodes: []
    name: input_length
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 1]
      dtype: int64
      name: label_length
      sparse: false
    inbound_nodes: []
    name: label_length
  - class_name: Lambda
    config:
      arguments: {}
      function: !!python/tuple ['4wEAAAAAAAAABQAAAAUAAABDAAAAczYAAAB8AFwEfQF9An0DfQR8AWQAZACFAmQBZACFAmQAZACF

          AmYDGQB9AXQAagF8AnwBfAN8BIMEUwApAk7pAgAAACkC2gFL2g5jdGNfYmF0Y2hfY29zdCkF2gRh

          cmdz2gZ5X3ByZWTaBmxhYmVsc9oMaW5wdXRfbGVuZ3Ro2gxsYWJlbF9sZW5ndGipAHIJAAAA+gxp

          bWFnZV9vY3IucHnaD2N0Y19sYW1iZGFfZnVuY2IBAABzBgAAAAABDAMaAQ==

          ', null, null]
      function_type: lambda
      name: ctc
      output_shape: !!python/tuple [1]
      output_shape_type: raw
      trainable: true
    inbound_nodes:
    - - - softmax
        - 0
        - 0
        - &id008 {}
      - - the_labels
        - 0
        - 0
        - *id008
      - - input_length
        - 0
        - 0
        - *id008
      - - label_length
        - 0
        - 0
        - *id008
    name: ctc
  name: model_2
  output_layers:
  - [ctc, 0, 0]
keras_version: 2.2.4
